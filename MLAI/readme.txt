The data is an instrument readout and are process values, most likely millibar. I can't discuss anything more on the process side. You have to handle it as data and data analysis.
Lines, subgroups and groups are explained like this: each line is a segment of a continuous process in a plant/equipment.
Each segment has a distinct condition or flavour. Five segments together form a subgroup. The subgroups consist of 5 lines. And then, seven subgroups were together from a group which is a significant division of the process.
The process involves various ingredients and vacuum/low pressure. The numbers indicate a particular process condition. Prime values are the desired process conditions. The values keep changing depending on the change of ingredients. I will not be able to give more info on the process side. We need to process it as data.

The program you would code together will read the data sets, all of them, and then understand the relations between the numbers, the lines, subgroups and the whole process.

The process is 245 lines- 49 subgroups - 7 groups.

The program will give a final list or “pattern” of the prime process value numbers for the whole process.

The maximum prime process value that can be there in a line is six. Which is also the same for the whole process. A process can have a max of six prime process values.

So, your program may first guess a “pattern” for each of the 49 subgroups, then guess 7 patterns for seven groups from the 49 subgroup patterns and finally, one process pattern from the seven group patterns.

The program is allowed to guess up to 9 values. If one gets 6 correct out of nine, that is a 100% score which would be very difficult.

We consider getting 4 to 5 right out of nine in one process or data set acceptable. There is some flexibility allowed. Instead of nine, it is allowed to guess 10 or 11 and get 4 to 5 correct out of 9, 10 or 11.

To start with, we have to target to get 4 to 5 correct out of nine.

See the example of one program output just for your understanding. This program is also in development.

This program is under development by another source and is currently able to correctly guess 2 out of nine in some attempts and up to 4 out of nine in some.

That program is not in the same route I am trying with you. That program uses ML algorithms to predict patterns from each data set OR one process. The developer has tried both ML and Neural Networks. It can get 2 to 4 out of nine and is not consistent.

That program is not by studying so many datasets as I want you to try. I want your program to predict based on the knowledge from as many data sets as possible. As it adds more and more data sets, it increases its library content and then uses all that information to make its prediction more and more accurate. That is how you have to code the program. As you increase the number of data sets analysed and added to the library, the chances of increasing the prediction accuracy also increase.

Over time there could be 100s of data sets in the program’s library. You have to code together a program that would study a large number of data sets and then make the “guessing” OR prediction to give out a process pattern for every new data set introduced to it.

I have access to 30 to 40 data sets right now, and I can share them with you for your trial programming and a demo. We could say the program works if you consistently demo a minimum threshold result of 4 out of nine.

The next stage would be to enter into a programming task to start with, say, 50 or 60 data sets and start predicting from the 61st data sets onwards. When the programme studies the 80 to 100th data set, it must give an output of 5 correct out of nine or ten values. As mentioned above, there is some flexibility. Nine could be ten as well or even 11, but to start with, let us aim to get 5 out of nine.

Any possible task based on the demo will also be in two parts. The first part is a demo based on a more significant number of data sets. Say, 50 or 60 data sets and then start predicting from the 61st data set onwards. As you predict up to 80 or 100 data sets, there must be a consistent result of 5 out of nine per process.

We will take it step by step , for the task demo part will determine fixed based on the knowledge you gain from the trial demo of 20 – 40 data sets. If the task demo of 60-100 data sets is consistent with a result of 5 correct out of nine per process, the option of moving ahead with the project will be considered.You will have to develop a proper interface for the program and make it a standalone application ready to be used by the users.

So, any possible task will be in two parts, a task demo part involving a minimum of 60-100 data sets and then developing the program into an app with the interface and all features against a price to be fixed at the end of the task demo.

The values in column C of the second sheet if there is a prime Process value in that line or if it is a “Nil” line. For example, line 1 of data set 1 is a “Nil” line. This means that there is no prime value in this line.

As you can observe, the first three lines have a Nil value. Means no prime process values. 4th line has just one prime value:13, and the 5th line has two prime values: 13 and 38, and so on. The values in C are either “Nil” or one prime value of that line. And the values in “D, E, F up to H, as available, are the prime process values in that line.

It is the prime process value and not the position of the prime value. Normal occurrence max is four values per line, and 6 per line is also there.

I hope you have some idea now. If you can make a demo asap, in a matter of a couple of days, it would be helpful. Let us say the demo by studying 20-40 data sets. If this works for you, I can send you 20 data sets immediately upon your confirmation. You study these twenty data sets and make the program ready.

I shall give the 21st data set without sheet 2. Your demo program has to pick up the values of sheet 2 of the 21st data set by itself. Like this, I shall give you up to 20 more data sets from 21st to the 40th without sheet 2.

And by the time your program guesses the sheet two values for the 40th data set, the program would have learned how to do it and then give a good, respectable output. So, your program will be designed to accommodate up to, say, 40 data sets to start with.

We can get into a agreement mode if your demo is promising with respectable results. And this has to be done pretty fast. Please, let me know how fast. I am ready for a video conference at your desired time.

First, study the above and let me know. I can send you the 20 data sets as soon as you tell me. Once that is studied and you understand the project, we can have the video conference. So, all your doubts can be cleared in one go. The minimum threshold output for the demo to succeed is consistently four correct out of nine.

The range of the values is 1 to 49. There are sometimes “Nil” lines in some subgroups. The first line of some of the subgroups is without any measured value. They are “Nil” lines without any measurements. And they are not “zero” value lines.

Please do ask if you need any more info.



QUESTION:

Is it to be done in parts or all at one shot ? 

Answer:

It is better done all on the one go or with a solution that gives out 49 subgroup patterns, 7 group patterns and a process pattern per process. As explained, a process is 245 lines, 49 subgroups and seven groups. Attaching a "test" Xlsx. Which is a sample output from a different app under development. As explained before, it can predict up to 2 out of nine and occasionally 4 out of nine per process . Still it has not reached the threshold level of 4 out of nine consistently.
